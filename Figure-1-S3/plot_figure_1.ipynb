{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c55d85-14a7-4a0f-a4c7-f7f8a151137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pytz\n",
    "import geopandas as gpd\n",
    "from datetime import datetime, timedelta\n",
    "import scipy.io as sio\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.backend import clear_session\n",
    "from scipy.stats import spearmanr, rankdata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from coastsat_keras import *\n",
    "\n",
    "import pyfes\n",
    "import os\n",
    "import CoastSat_slope.SDS_slope as SDS_slope\n",
    "\n",
    "transect_data = gpd.read_file('data_coastsat/transects_edit.geojson')\n",
    "transect_data = transect_data[transect_data['id'].str.contains(\"usa_CA\")]\n",
    "def linestring_to_points(feature,line):\n",
    "    return line.coords\n",
    "\n",
    "transect_data['points'] = transect_data.apply(lambda l: linestring_to_points(l['site_id'],l['geometry']), axis=1)\n",
    "site_id = transect_data['id'].to_numpy()\n",
    "\n",
    "shore_data_new = pd.read_csv('CoastSat/All_CA_April_2023.csvx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdbf064-b0be-4ce9-bc81-75c731eb1495",
   "metadata": {},
   "outputs": [],
   "source": [
    "beach_id = 'usa_CA_0011-0014'\n",
    "shore_data,tide_heights,wave_data,dist_mop,spec1d_interp,freqz = read_shore_data_new(beach_id,site_id,shore_data_new)\n",
    "df, df_time = create_df_for_keras(shore_data,tide_heights,wave_data,spec1d_interp,freqz,beach_id)\n",
    "df_proj,mop_time = create_proj_data(beach_id,site_id)\n",
    "X_all,X_train,X_val,X_test,y_all,y_train,y_val,y_test,df_mean,df_std,X_proj = create_train_val_test_data_sequential(df,df_proj)\n",
    "model = read_keras_model(beach_id,site_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d921a20-3234-4e6d-86c9-ecca8c06a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "plt.close('all')\n",
    "fig, ((ax1),(ax0),(ax3)) = plt.subplots(nrows=3,ncols=1)\n",
    "plt.subplots_adjust(wspace=0.01)\n",
    "plt.subplots_adjust(hspace=0.15)\n",
    "fig.set_size_inches(9.25, 7.5)\n",
    "\n",
    "df_ = df.copy()\n",
    "n = len(df_)\n",
    "df_['dates'] = df_time\n",
    "\n",
    "train_df_ = df_[0:int(n*0.7)]\n",
    "val_df_ = df_[int(n*0.7):int(n*0.8)]\n",
    "test_df_ = df_[int(n*0.8):]\n",
    "df_ = df_.sort_values(by=['dates'])\n",
    "\n",
    "ax0.axhline(y=0,color='black',alpha=0.2)\n",
    "ax0.plot(df_['dates'],-1*(df_['shore_change'] - np.nanmean(df_['shore_change'])),color='black',alpha=0.3)\n",
    "ax0.plot(train_df_['dates'],-1*(train_df_['shore_change'] - np.nanmean(df_['shore_change'])),color=sns.color_palette(\"Paired\")[1],marker='.',linestyle=\"None\")\n",
    "ax0.plot(val_df_['dates'],-1*(val_df_['shore_change'] - np.nanmean(df_['shore_change'])),color=sns.color_palette(\"Paired\")[7],marker='.',linestyle=\"None\")\n",
    "ax0.plot(test_df_['dates'],-1*(test_df_['shore_change'] - np.nanmean(df_['shore_change'])),color=sns.color_palette(\"Paired\")[9],marker='.',linestyle=\"None\")\n",
    "ax0.set_xlim([pd.to_datetime('2000-01-01'),pd.to_datetime('2023-04-01')])\n",
    "# ax0.set_xticklabels([])\n",
    "ax0.text(pd.to_datetime('2002-11-01'),-55,'Satellite Observations\\n(Sequential Split)',fontsize=12,color='black',alpha=0.8)\n",
    "ax0.set_ylim([-60,45])\n",
    "ax0.text(pd.to_datetime('2000-02-01'),36,'(b)',fontsize=12,color='k')\n",
    "ax0.set_xticklabels([])\n",
    "ax0.set_ylabel('MSL Beach Width (m)')\n",
    "ax0.grid(axis='x')\n",
    "\n",
    "train_df__ = pd.read_csv('figure_data/train_df.csv')\n",
    "train_df__['dates'] = pd.to_datetime(train_df__['dates'], utc=True)\n",
    "val_df__ = pd.read_csv('figure_data/val_df.csv')\n",
    "val_df__['dates'] = pd.to_datetime(val_df__['dates'], utc=True)\n",
    "test_df__ = pd.read_csv('figure_data/test_df.csv')\n",
    "test_df__['dates'] = pd.to_datetime(test_df__['dates'], utc=True)\n",
    "\n",
    "ax1.axhline(y=0,color='black',alpha=0.2)\n",
    "ax1.plot(df_['dates'],(df_['shore_change'] - np.nanmean(df_['shore_change'])),color='black',alpha=0.3)\n",
    "ax1.plot(train_df__['dates'],(train_df__['shore_change'] - np.nanmean(df_['shore_change'])),color=sns.color_palette(\"Paired\")[1],marker='.',linestyle=\"None\")\n",
    "ax1.plot(val_df__['dates'],(val_df__['shore_change'] - np.nanmean(df_['shore_change'])),color=sns.color_palette(\"Paired\")[7],marker='.',linestyle=\"None\")\n",
    "ax1.plot(test_df__['dates'],(test_df__['shore_change'] - np.nanmean(df_['shore_change'])),color=sns.color_palette(\"Paired\")[9],marker='.',linestyle=\"None\")\n",
    "ax1.set_xlim([pd.to_datetime('2000-01-01'),pd.to_datetime('2023-04-01')])\n",
    "\n",
    "ax1.text(pd.to_datetime('2011-01-01'),38,'Training',fontsize=12,color=sns.color_palette(\"Paired\")[1])\n",
    "ax1.text(pd.to_datetime('2013-05-05'),38,'Validation',fontsize=12,color=sns.color_palette(\"Paired\")[7])\n",
    "ax1.text(pd.to_datetime('2016-02-15'),38,'Test',fontsize=12,color=sns.color_palette(\"Paired\")[9])\n",
    "ax1.text(pd.to_datetime('2004-11-01'),38,'Satellite Observations\\n(Random Split)',fontsize=12,color='black',alpha=0.8)\n",
    "ax1.set_ylim([-45,60])\n",
    "ax1.text(pd.to_datetime('2000-02-01'),52,'(a)',fontsize=12,color='k')\n",
    "ax1.set_xticklabels([])\n",
    "ax1.set_title('Observations and Deep Neural Network (DNN) Model Predictions at Torrey Pines')\n",
    "ax1.grid(axis='x')\n",
    "\n",
    "ind_mop = str(np.squeeze(np.argwhere(site_id==beach_id)) + 1)\n",
    "mop_fold = '../mop/MOP_Beach_Widths/MOP_Width_'\n",
    "beach_width = sio.loadmat(mop_fold + ind_mop + '.mat')    \n",
    "time_width = np.squeeze(beach_width['time_width'])\n",
    "time_width = pd.to_datetime(time_width-719529., unit='D')\n",
    "msl_width = -1*np.squeeze(beach_width['msl_width'])\n",
    "msl_width = msl_width - np.nanmean(msl_width)\n",
    "\n",
    "f2pd = np.loadtxt('figure_data/figure_1_panel_d.txt')\n",
    "first_non_nan_idx = np.where(~np.isnan(f2pd))[0][0]\n",
    "f2pd[first_non_nan_idx] = np.nan\n",
    "\n",
    "ax3.axhline(y=0,color='black',alpha=0.2)\n",
    "ax3.plot(time_width,-1*msl_width,color='black')\n",
    "f1pd = np.loadtxt('figure_data/figure_1_panel_d_seq.txt')\n",
    "first_non_nan_idx = np.where(~np.isnan(f1pd))[0][0]\n",
    "f1pd[first_non_nan_idx] = np.nan\n",
    "ax3.plot(time_width,-1*f1pd,color=sns.color_palette(\"Paired\")[5],linewidth=1)\n",
    "ax3.plot(time_width,-1*f2pd,color=sns.color_palette(\"Paired\")[3],linewidth=1)\n",
    "ax3.text(pd.to_datetime('2004-04-10'),40,'DNN Random',fontsize=12,color=sns.color_palette(\"Paired\")[3])\n",
    "ax3.text(pd.to_datetime('2004-04-10'),30,'DNN Sequential',fontsize=12,color=sns.color_palette(\"Paired\")[5])\n",
    "ax3.text(pd.to_datetime('2004-04-10'),50,'Surveys',fontsize=12,color='black')\n",
    "ax3.set_xlim([pd.to_datetime('2000-01-01'),pd.to_datetime('2023-04-01')])\n",
    "ax3.set_ylim([-45,60])\n",
    "ax3.text(pd.to_datetime('2000-02-01'),52,'(c)',fontsize=12,color='k')\n",
    "ax3.grid(axis='x')\n",
    "\n",
    "plt.savefig('figures/TPSB_predictions_sequential.pdf',bbox_inches='tight')\n",
    "plt.savefig('figures/TPSB_predictions_sequential.png',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "f1pd = -1*f1pd\n",
    "msl_width = -1*msl_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3d90cf-96c6-43d4-962e-7e35bc0d9b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def find_closest(df_list, date):\n",
    "    closest_dates = [df['dates'].iloc[np.argmin(np.abs(df['dates'] - date))] for df in df_list]\n",
    "    min_diff = min([abs(date - d) for d in closest_dates])\n",
    "    for i, d in enumerate(closest_dates):\n",
    "        if abs(date - d) == min_diff:\n",
    "            return i + 1\n",
    "    return None\n",
    "\n",
    "# Apply the function to each date in time_width\n",
    "results = [find_closest([train_df_, val_df_, test_df_], date) for date in time_width.tz_localize('UTC')]\n",
    "\n",
    "plt.close('all')\n",
    "fig, ((ax1),(ax0)) = plt.subplots(nrows=1,ncols=2)\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "plt.subplots_adjust(hspace=0.15)\n",
    "fig.set_size_inches(6.25, 3.25)\n",
    "\n",
    "cp = [sns.color_palette(\"Paired\")[1],sns.color_palette(\"Paired\")[7],sns.color_palette(\"Paired\")[9]]\n",
    "\n",
    "idx_nan = np.isnan(f1pd)\n",
    "msl_width_ = msl_width.copy()\n",
    "f1pd = (f1pd - np.nanmedian(f1pd))\n",
    "indices_where_one = np.where(np.array(results) == 1)[0]\n",
    "ax0.scatter(x = msl_width_[indices_where_one],y = f1pd[indices_where_one], color = sns.color_palette(\"Paired\")[1],marker='.',s=20)\n",
    "indices_where_one = np.where(np.array(results) == 2)[0]\n",
    "ax0.scatter(x = msl_width_[indices_where_one],y = f1pd[indices_where_one], color = sns.color_palette(\"Paired\")[7],marker='.',s=20)\n",
    "indices_where_one = np.where(np.array(results) == 3)[0]\n",
    "ax0.scatter(x = msl_width_[indices_where_one],y = f1pd[indices_where_one], color = sns.color_palette(\"Paired\")[9],marker='.',s=20)\n",
    "ax0.set_aspect('equal', adjustable='box')\n",
    "ax0.set_xlabel('Survey Beach Width (m)',fontsize=10)\n",
    "ax0.set_title('Sequential Split',fontsize=10)\n",
    "\n",
    "# Create a 1:1 line\n",
    "x = np.linspace(start=-50, stop=50, num=1000)\n",
    "y = x\n",
    "ax0.plot(x, y, label='y = x', color='black')\n",
    "ax0.set_xlim([-25,40])\n",
    "ax0.set_ylim([-25,40])\n",
    "\n",
    "ax0.text(33,-23,'(e)',fontsize=10)\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "idx_nan_r2 = np.isnan(f1pd[indices_where_one])\n",
    "nmse_f1pd = rmse(f1pd[indices_where_one][~idx_nan_r2],msl_width[indices_where_one][~idx_nan_r2])\n",
    "# nmse_f1pd_mean = rmse(np.mean(msl_width[indices_where_one][~idx_nan_r2]),msl_width[indices_where_one][~idx_nan_r2])\n",
    "nmse_f1pd_mean = rmse(np.mean(f1pd[indices_where_one][~idx_nan_r2]),f1pd[indices_where_one][~idx_nan_r2])\n",
    "ax0.text(-23,35,'RMSE (Test): '+ str(np.round(nmse_f1pd*100)/100)+ ' m',fontsize=10)\n",
    "\n",
    "idx_nan_r2 = np.isnan(f1pd[indices_where_one])\n",
    "skill_f1pd = 1 - nmse_f1pd**2/nmse_f1pd_mean**2\n",
    "\n",
    "ax0.text(-23,30,'Skill (Test): '+ str(np.round(skill_f1pd*100)/100),fontsize=10)\n",
    "\n",
    "f2pd = np.loadtxt('figure_data/figure_1_panel_d.txt')\n",
    "f2pd = -1*f2pd\n",
    "results_ = np.loadtxt('figure_data/figure_1_panel_scatter.txt')\n",
    "indices_where_one = np.where(np.array(results_) == 1)[0]\n",
    "ax1.scatter(x = msl_width_[indices_where_one],y = f2pd[indices_where_one], color = sns.color_palette(\"Paired\")[1],marker='.',s=20)\n",
    "indices_where_one = np.where(np.array(results_) == 2)[0]\n",
    "ax1.scatter(x = msl_width_[indices_where_one],y = f2pd[indices_where_one], color = sns.color_palette(\"Paired\")[7],marker='.',s=20)\n",
    "indices_where_one = np.where(np.array(results_) == 3)[0]\n",
    "ax1.scatter(x = msl_width_[indices_where_one],y = f2pd[indices_where_one], color = sns.color_palette(\"Paired\")[9],marker='.',s=20)\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "idx_nan_r2 = np.isnan(f2pd)\n",
    "ax1.set_ylabel('DNN Beach Width (m)',fontsize=10)\n",
    "\n",
    "idx_nan_r2 = np.isnan(f2pd[indices_where_one])\n",
    "nmse_f2pd = rmse(f2pd[indices_where_one][~idx_nan_r2],msl_width[indices_where_one][~idx_nan_r2])\n",
    "# nmse_f2pd_mean = rmse(np.mean(msl_width[indices_where_one][~idx_nan_r2]),msl_width[indices_where_one][~idx_nan_r2])\n",
    "nmse_f2pd_mean = rmse(np.mean(f2pd[indices_where_one][~idx_nan_r2]),f2pd[indices_where_one][~idx_nan_r2])\n",
    "ax1.text(-23,35,'RMSE (Test): '+ str(np.round(nmse_f2pd*100)/100)+ ' m',fontsize=10)\n",
    "\n",
    "idx_nan_r2 = np.isnan(f2pd[indices_where_one])\n",
    "skill_f2pd = 1 - nmse_f2pd**2/nmse_f2pd_mean**2\n",
    "\n",
    "ax1.text(-23,30,'Skill (Test): '+ str(np.round(skill_f2pd*100)/100),fontsize=10)\n",
    "\n",
    "# Create a 1:1 line\n",
    "x = np.linspace(start=-50, stop=50, num=1000)\n",
    "y = x\n",
    "ax1.plot(x, y, label='y = x', color='black')\n",
    "ax1.set_xlim([-25,40])\n",
    "ax1.set_ylim([-25,40])\n",
    "\n",
    "ax1.text(33,-23,'(d)',fontsize=10)\n",
    "\n",
    "ax1.set_xlabel('Survey Beach Width (m)',fontsize=10)\n",
    "ax1.set_title('Random Split',fontsize=10)\n",
    "\n",
    "\n",
    "plt.savefig('figures/TPSB_predictions_sequential_scatter.pdf',bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
